# 2021-09-17

# HDFS

## 공식 문서에서 소개하는 HDFS

(참고 : [https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html](https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html))

- HDFS는 장애에 매우 강하고, 저렴한 하드웨어에 배포할 수 있도록 디자인 됨
- HDFS는 애플리케이션 데이터에 접근할 때 높은 throughput을 제공함. 따라서 큰 데이터 셋을 갖는 애플리케이션에 적합함
- HDFS는 파일 시스템 데이터에 대한 스트리밍 접근을 가능하게 하기 위해 몇 가지 POSIX 요구 사항(?)을 완화함 → 뭔 말임? 안 지켰다는 소린가?

## HDFS 아키텍처

![https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/images/hdfsarchitecture.png](https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/images/hdfsarchitecture.png)

- HDFS는 마스터/슬레이브 구조를 가짐
- NameNode : 단일 마스터 서버로 파일 시스템 namespace를 관리하고 클라이언트의 파일 접근을 제어
    - 파일 및 디렉터리 열기, 닫기, 이름 바꾸기와 같은 파일 시스템 namespace 제어 작업을 수행
    - DataNode에 대한 블록 매핑을 결정 → 파일을 어디에 보관할지를 결정한다는건가?
    - → 왜 단일일까? HA 구성을 하지 않아도 괜찮은건가? 아닌데.. 반드시 해야할거같은데 ㅋㅋㅋㅋ 이거 단일 네임노드 fail 시에는 원하는 파일의 메타데이터를 읽을 수가 없으니 어떤 데이터 노드에 분산 보관되어 있는지 알 길이 없잖아?
    - Q. 여기서 말하는 namespace는 어떤 의미?
- DataNode : 여러 슬레이브 서버로 HDFS 클러스터의 노드당 하나씩 실행되는 노드에 연결된 스토리지를 관리
    - 파일 시스템 클라이언트의 읽기 및 쓰기 요청을 처리하는 역할
- HDFS는 파일 시스템 namespace를 노출하고, 사용자 데이터를 파일에 저장할 수 있도록 함
    - 내부적으로는 파일이 하나 이상의 블록으로 분할되고, 이러한 블록은 DataNode 집합에 보관됨
    - 

## 블로그 참고

참고 : [https://dabingk.tistory.com/2](https://dabingk.tistory.com/2)

Hadoop Distributed File System

대용량의 파일을 분산 서버에 저장하고, 그 데이터를 빠르게 처리할 수 있도록 설계한 파일 시스템

아룬 머시 : 하둡 네트워크에 연결된 아무 기기에나 데이터를 밀어 넣는 분산형 파일시스템으로 RDBMS의 고도로 엄격한 저장 인프라에 견줘보면 돼지우리나 다름 없다.. ㅋㅋㅋ

## 특징

- 대용량 데이터 저장
    - HDFS는 하나의 파일이 GB에서 TB이상의 크기로 저장될 수 있음
- 데이터 무결성
    - DB의 데이터 무결성이란, DB에 저장되는 데이터가 일관성을 갖는 것을 의미함. 이를 위해 데이터의 입력이나 변경을 막아, 데이터의 안정성을 유지함. → 데이터의 안정성을 유지하기 위해 HDFS에선 한 번 저장된 데이터는 수정할 수 없고, 읽기만 가능함. 다만, 수정은 불가능하지만, 파일 이동, 삭제, 복사는 가능함.
- 장애 복구
    - HDFS는 장애를 빠른 시간에 감지하고 대처할 수 있게 도와줌
    - 데이터를 보관하면, 복제 데이터도 함께 보관되어 데이터의 유실을 방지함
    - 분산 서버끼리 주기적으로 상태를 체크해서 빠른 시간 안에 장애를 인지함(기본 블록당 3개를 복제하여 다른 데이터 노드에 보관) → NameNode가 클러스터의 각 DataNode로부터 주기적으로 Hearbeat 및 Blockreport를 수신 → Heartbeat를 수신하였다는 것은 DataNode가 제대로 작동하고 있음을 의미하며, Blockreport에는 DataNode의 모든 블록 리스트 정보가 포함됨..?
- 스트리밍 방식의 데이터 접근
    - HDFS는 클라이언트의 요청을 빠른 시간 내에 처리하는 것보다 **동일한 시간 내에 더 많은 데이터를 처리하도록 설계되었음** ('빠른 시간 내의 데이터 처리' <<<<< '데이터의 양')
    - 이를 위해 클라이언트는 끊김 없는 연속된 흐름으로 데이터에 접근해야 함

## Data Lake

하둡을 Data Lake라고도 표현함. Data Lake는 막대한 양의 원본 데이터나 세분화된 데이터를 Access Point까지 Native 형식으로 보관하는 스토리지. 

- Access Point는 무엇이며 Native 형식이라는 것은 무엇인가?

## 블록 구조 파일 시스템

- Hadoop 2.X 기준으로 1개의 블록이 128MB (Hadoop 1.X는 64MB)
- 일반적인 파일 시스템의 블록 크기가 4~8KB인데, 이에 비해 압도적으로 큼
- 이유는
    1. Disk Seek Time을 줄이기 위함
        - 일반적인 disk seek time은 10ms이고 disk tx bandwidth는 100MB/s임
        - HDFS는 disk seek time이 disk tx bandwidth의 1%만을 사용하고자 하기 때문에 100MB에 근접한 64MB를 사용... → 뭔 소리지? ㅋㅋㅋㅋㅋㅋ
    2. NameNode가 유지하는 metadata의 크기를 줄이기 위함
        - metadata란 데이터의 정보를 담은 데이터(데이터의 데이터) → 블록의 위치, 파일명, 디렉터리 구조, 권한 정보 등이 해당됨
        - NameNode란 하둡의 마스터 서버를 의미하며, 슬레이브 서버인 DataNode를 관리함
        - 200MB의 데이터를 저장한다면, 2개의 블록으로 파일을 쪼개게 될 것이고, NameNode는 두 개의 블록에 대한 메타데이터만 저장하고 관리하면 됨
            - 반면에 기존 4 ~8KB의 블록 크기를 사용하는 파일 시스템에선 메타데이터가 최소 25개 이상.. (왜..?) 생성될 것임
            - 메타데이터를 적게 하면 클라이언트와 NameNode 간의 통신 횟수가 줄어들게 됨
            - 예를 들어, 클라이언트가 하둡에 데이터를 쓰거나 읽고 싶어한다면, 클라이언트는 NameNode 부터 접근해서 원하는 데이터의 위치를 알아내야 함 → 이 때 메타데이터의 개수가 적으면 클라이언트가 NameNode로 접근하는 횟수가 줄어듦
